{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSIytlo05vcL",
        "outputId": "1e144cb7-8302-469f-8eab-ea21e703525b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import glob\n",
        "import cv2\n",
        "import os\n",
        "import keras_tuner as kt\n",
        "import keras as k\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OdOTVHHyz0v",
        "outputId": "71e3d298-5fab-4c79-f7ea-640ad8d39d7e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.6-py3-none-any.whl (128 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/128.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m122.9/128.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.9/128.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2023.11.17)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.6 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir(\"/gdrive/My Drive/DerinÖğrenme/Pneumonia/X-Ray\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfsctyShy_7c",
        "outputId": "401c94e3-ca49-4192-b623-2e426392b280"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Bacterial', 'Viral']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATADIR = '/gdrive/My Drive/DerinÖğrenme/Pneumonia/X-Ray'\n",
        "CATEGORIES = [\"Bacterial\",\"Viral\"]"
      ],
      "metadata": {
        "id": "GIYhzYHCzZRs"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 250"
      ],
      "metadata": {
        "id": "qc3kJ8pWzoSY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Boş bir liste oluşturuluyor, burada özellikler ve etiketler depolanacak.\n",
        "all_data =[]\n",
        "\n",
        "def create_all_data():\n",
        "  # Tanımlanan sınıfların her biri üzerinde dönülüyor.\n",
        "    for category in CATEGORIES:\n",
        "       # Sınıfa ait dosya yolu oluşturuluyor.\n",
        "        path=os.path.join(DATADIR, category)\n",
        "        # Sınıf numarası belirleniyor.\n",
        "        class_num=CATEGORIES.index(category)\n",
        "        # Belirtilen sınıfın dosya dizini içindeki her bir görüntü dosyası üzerinde dönülüyor.\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "              # Görüntü dosyasını okuyor.\n",
        "                img_array=cv2.imread(os.path.join(path,img))\n",
        "                # Görüntüyü belirli bir boyuta yeniden boyutlandırıyor.\n",
        "                new_array=cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\n",
        "                # Yeni özellik ve etiket, all_data listesine ekleniyor.\n",
        "                all_data.append([new_array,class_num])\n",
        "            except Exception as e:\n",
        "              # Görüntü okuma veya boyutlandırma sırasında hata alınırsa, hatay görmezden geliniyor.\n",
        "                pass\n",
        "create_all_data()"
      ],
      "metadata": {
        "id": "8CoMbp8Kzqro"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total number of images: \", len(all_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qI0uw48W37Vd",
        "outputId": "041a106c-eb47-4950-9094-b58c86507c3b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of images:  16167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Özellikleri (görüntü verileri) tutacak liste\n",
        "X = []\n",
        "# Etiketleri (sınıf numaraları) tutacak liste\n",
        "y = []\n",
        "\n",
        "for categories, label in all_data:\n",
        "  X.append(categories)\n",
        "  y.append(label)"
      ],
      "metadata": {
        "id": "3ZbmFYyw39YY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Veriyi eğitim ve test setlerine ayırma işlemi\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state =42)\n",
        "\n",
        "# Eğitim setini daha fazla bölme, bu sefer eğitim ve doğrulama setleri oluşturuluyor\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.10, random_state=42)"
      ],
      "metadata": {
        "id": "wVJxf-hU4BA9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eğitim setini NumPy dizisine dönüştürme\n",
        "x_train = np.array(x_train)\n",
        "x_test = np.array(x_test)\n",
        "\n",
        "# Test setini NumPy dizisine dönüştürme\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "# Doğrulama setini NumPy dizisine dönüştürme\n",
        "x_val = np.array(x_val)\n",
        "y_val = np.array(y_val)"
      ],
      "metadata": {
        "id": "qKQ2v96G4Fhe"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(x_val.shape)\n",
        "\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "print(y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6Xu7f4W4LOb",
        "outputId": "de708ded-daf9-4481-b25e-b54ad26cd9cd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11639, 250, 250, 3)\n",
            "(3234, 250, 250, 3)\n",
            "(1294, 250, 250, 3)\n",
            "(11639,)\n",
            "(3234,)\n",
            "(1294,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# Eğitim setindeki sınıfları ikili formata dönüştürme\n",
        "train_yCl = tf.keras.utils.to_categorical(y_train, num_classes=2)\n",
        "# Test setindeki sınıfları ikili formata dönüştürme\n",
        "test_yCl = tf.keras.utils.to_categorical(y_test, num_classes=2)\n",
        "# Doğrulama setindeki sınıfları ikili formata dönüştürme\n",
        "valid_yCl = tf.keras.utils.to_categorical(y_val, num_classes=2)"
      ],
      "metadata": {
        "id": "sDrqCJfl4TIV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense, Activation, BatchNormalization, Flatten, Conv2D, MaxPooling2D, Dropout, AveragePooling2D\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "# CNN modelinin tanımlanması\n",
        "def cnnModel(hp):\n",
        "  model = Sequential()\n",
        "\n",
        "  hp_LR = hp.Choice('learning_rate',\n",
        "                    values = [1e-2, 1e-3, 1e-4])\n",
        "\n",
        "  hp_filters = hp.Int('filters_hp',\n",
        "                      min_value = 32,\n",
        "                      max_value = 512,\n",
        "                      step = 32)\n",
        "\n",
        "  hp_dropout = hp.Float('dropout',\n",
        "                        0.2,\n",
        "                        0.5,\n",
        "                        step=0.05,\n",
        "                        default=0.5)\n",
        "  hp_unit = hp.Int('units',\n",
        "                    min_value=128,\n",
        "                    max_value=1024,\n",
        "                    step=128)\n",
        "\n",
        "\n",
        "  for i in range(hp.Int('conv_blocks', 3, 4, 5, default=3)):\n",
        "      for _ in range(2):\n",
        "        model.add(Conv2D(hp_filters, (3, 3), padding=\"Same\", input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
        "        model.add(Activation('relu'))\n",
        "        if hp.Choice('pooling_' + str(i), ['avg', 'max']) == 'max':\n",
        "          model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        else:\n",
        "          model.add(AveragePooling2D(pool_size=(2, 2)))\n",
        "      model.add(BatchNormalization())\n",
        "      # Overfittingi azaltır.\n",
        "      model.add(Dropout(0.13))\n",
        "\n",
        "  # Tam Bağlantılı (Fully Connected) Katmanlar\n",
        "  model.add(Flatten())\n",
        "  model.add(Dropout(hp_dropout))\n",
        "  model.add(Dense(hp_unit))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(hp_dropout))\n",
        "  model.add(Dense(hp_unit))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dense(2))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "  optimizer = tf.keras.optimizers.legacy.Adam(\n",
        "    learning_rate = hp_LR,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    name='Adam'\n",
        "  )\n",
        "\n",
        "# Optimizasyon ve model derleme\n",
        "  model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "BuDWlRGm4dRT"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "# En iyi performans gösteren modelin ağırlıkları kaydeder.\n",
        "callback_list = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath='model.h5',\n",
        "        # Sadece en iyi modeli kaydet\n",
        "        monitor = 'val_accuracy', save_best_only=True, verbose=3\n",
        "    ),\n",
        "     # EarlyStopping callback'i, 'val_loss' metriği üzerinde belirtilen sabır süresi (3) boyunca bir iyileşme olmadığında eğitimi durdurur.\n",
        "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, verbose=3)\n",
        "]\n"
      ],
      "metadata": {
        "id": "9p0dg8R14fQG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keras Tuner'ın RandomSearch metodunu kullanılır.\n",
        "tuner = kt.RandomSearch(\n",
        "\t\thypermodel = cnnModel,\n",
        "\t\toptimizer=keras.optimizers.Adam(),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=['accuracy'],\n",
        "\t\t# Optimizasyon hedefi\n",
        "\t\tobjective=\"val_accuracy\",\n",
        "\t\t# Deneme sayısı\n",
        "\t\tmax_trials=6,\n",
        "\t\t# Rastgele sayı üretimi için kullanılan tohum değeri\n",
        "\t\tseed=42,\n",
        "\t\t)\n",
        "\n",
        "# Modeli eğitirken kullanılan veri ve diğer parametreler belirtiliyor.\n",
        "tuner.search(\n",
        "\tx=x_train, y=train_yCl,\n",
        "\tvalidation_data=(x_val, valid_yCl),\n",
        "\t# Eğitim sırasında kullanılacak callback'ler\n",
        "\tcallbacks=  callback_list,\n",
        "\t# Eğitim epoch sayısı\n",
        "\tepochs = 15\n",
        ")\n",
        "\n",
        "# Hiperparametre araştırması sonuçları özetleniyor.\n",
        "tuner.search_space_summary(extended=True)\n",
        "\n",
        "# En iyi hiperparametre setini alıyoruz.\n",
        "best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "# En iyi hiperparametre seti ile bir model oluşturuluyor.\n",
        "model = tuner.hypermodel.build(best_hp)\n",
        "\n",
        "# Oluşturulan modeli kullanarak eğitim başlatılıyor.\n",
        "history = model.fit(x_train, train_yCl, validation_data=(x_val, valid_yCl), batch_size=64, epochs=30, callbacks = callback_list, verbose=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "cuhWk1VM4mJU",
        "outputId": "9ba5ac3a-7353-4113-d877-7145fba9165a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'kt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c5d32a966550>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Keras Tuner'ın RandomSearch metodunu kullanılır.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m tuner = kt.RandomSearch(\n\u001b[0m\u001b[1;32m      3\u001b[0m                 \u001b[0mhypermodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnnModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'kt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "VqNnOJ0dAtka",
        "outputId": "3fbb038d-3f28-4e6a-b3d7-7967756a5c36"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3caefa261807>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test seti üzerinde modelin performansını değerlendirme\n",
        "score_test = model.evaluate(x_test, test_yCl)\n",
        "print(\"Accuracy: \", score_test[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "QVeUE6UDBDgs",
        "outputId": "d307111d-f4ad-435d-9520-fc7f2584b087"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-a509a5c9b496>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Test seti üzerinde modelin performansını değerlendirme\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscore_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_yCl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3981\u001b[0m         \u001b[0;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3982\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3983\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   3984\u001b[0m                 \u001b[0;34m\"You must compile your model before \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3985\u001b[0m                 \u001b[0;34m\"training/testing. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "def plot_confusion_matrix(cm, classes, normalize=True, title='Confusion matrix', cmap=plt.cm.Reds):\n",
        "\n",
        "    # Figür boyutu belirleniyor\n",
        "    plt.figure(figsize=(3,3))\n",
        "    # Matris renkli bir görüntüleme ile çiziliyor\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    # Grafik başlığı ayarlanıyor\n",
        "    plt.title(title)\n",
        "    # Renk skalası ekleniyor\n",
        "    plt.colorbar()\n",
        "    # Eksen etiketleri belirleniyor\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    # Normalizasyon işlemi kontrol ediliyor\n",
        "    if normalize:\n",
        "      # Normalizasyon işlemi\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        cm = np.around(cm, decimals=2)\n",
        "        cm[np.isnan(cm)] = 0.0\n",
        "    # Matris hücrelerine değerleri eklemek için eşleştirme yapılıyor\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    # Eksen etiketleri düzenleniyor\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "metadata": {
        "id": "6ZxC8R_ZBJoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "def evaluate_model(model, x_test, y_test):\n",
        "    # Accuracy Score\n",
        "    y_pred = model.predict(x_test)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_test_classes = np.argmax(test_yCl, axis=1)\n",
        "    accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "    # Precision Score\n",
        "    precision = precision_score(y_test_classes, y_pred_classes, average='weighted')\n",
        "    print(f\"Precision: {precision}\")\n",
        "\n",
        "    # Recall Score\n",
        "    recall = recall_score(y_test_classes, y_pred_classes, average='weighted')\n",
        "    print(f\"Recall: {recall}\")\n",
        "\n",
        "    # F1 Score\n",
        "    f1 = f1_score(y_test_classes, y_pred_classes, average='weighted')\n",
        "    print(f\"F1-Score: {f1}\")\n",
        "\n",
        "    # Classification Report\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test_classes, y_pred_classes))\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_test_classes, y_pred_classes)\n",
        "    classes = [\"Tumor\",\"Normal\"]\n",
        "    plot_confusion_matrix(cm, classes, title='Confusion Matrix')\n",
        "\n",
        "# Modeli değerlendir\n",
        "evaluate_model(model, x_test, y_test)\n"
      ],
      "metadata": {
        "id": "KKzfpJODBVTo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}